{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07643dc8",
   "metadata": {},
   "source": [
    "# 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb033ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7aa6b",
   "metadata": {},
   "source": [
    "# 2. Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CarRacing-v0')\n",
    "        self.reward_threshold = self.env.spec.reward_threshold\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "        self.av_r = self.reward_memory()\n",
    "        self.die = False\n",
    "        img_rgb = self.env.reset()\n",
    "        img_gray = self.rgb2gray(img_rgb)\n",
    "        self.stack = [img_gray] * 4\n",
    "        return np.array(self.stack)\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        for i in range(8):\n",
    "            img_rgb, reward, die, _ = self.env.step(action)\n",
    "            # don't penalize \"die state\"\n",
    "            if die:\n",
    "                reward += 100\n",
    "            # green penalty\n",
    "            if np.mean(img_rgb[:, :, 1]) > 185.0:\n",
    "                reward -= 0.05\n",
    "            total_reward += reward\n",
    "            # if no reward recently, end the episode\n",
    "            done = True if self.av_r(reward) <= -0.1 else False\n",
    "            if done or die:\n",
    "                break\n",
    "        img_gray = self.rgb2gray(img_rgb)\n",
    "        self.stack.pop(0)\n",
    "        self.stack.append(img_gray)\n",
    "        assert len(self.stack) == 4\n",
    "        return np.array(self.stack), total_reward, done, die\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    @staticmethod\n",
    "    def rgb2gray(rgb, norm=True):\n",
    "        gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n",
    "        if norm:\n",
    "            # normalize\n",
    "            gray = gray / 128. - 1.\n",
    "        return gray\n",
    "\n",
    "    @staticmethod\n",
    "    def reward_memory():\n",
    "        count = 0\n",
    "        length = 100\n",
    "        history = np.zeros(length)\n",
    "\n",
    "        def memory(reward):\n",
    "            nonlocal count\n",
    "            history[count] = reward\n",
    "            count = (count + 1) % length\n",
    "            return np.mean(history)\n",
    "\n",
    "        return memory\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn_base = nn.Sequential(  # input shape (4, 96, 96)\n",
    "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
    "            nn.ReLU(),  # activation\n",
    "        )  # output shape (256, 1, 1)\n",
    "        self.v = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n",
    "        self.fc = nn.Sequential(nn.Linear(256, 100), nn.ReLU())\n",
    "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
    "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
    "        self.apply(self._weights_init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _weights_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_base(x)\n",
    "        x = x.view(-1, 256)\n",
    "        v = self.v(x)\n",
    "        x = self.fc(x)\n",
    "        alpha = self.alpha_head(x) + 1\n",
    "        beta = self.beta_head(x) + 1\n",
    "\n",
    "        return (alpha, beta), v\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.net = Net().float().to(device)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.from_numpy(state).float().to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            alpha, beta = self.net(state)[0]\n",
    "        action = alpha / (alpha + beta)\n",
    "\n",
    "        action = action.squeeze().cpu().numpy()\n",
    "        return action\n",
    "\n",
    "    def load_param(self):\n",
    "        self.net.load_state_dict(torch.load('param/expert.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4537e",
   "metadata": {},
   "source": [
    "# 3. Save trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc4b898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1141..1430 -> 289-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awds2588\\anaconda3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 執行緒模式設定後就不能再變更它。\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "Ep 0\tScore: 5.33\t\n",
      "0 1\n",
      "Track generation: 1293..1620 -> 327-tiles track\n",
      "Ep 1\tScore: 3.90\t\n",
      "1 3\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "Ep 2\tScore: 6.83\t\n",
      "2 3\n",
      "Track generation: 1112..1399 -> 287-tiles track\n",
      "Ep 3\tScore: 6.08\t\n",
      "3 4\n",
      "Track generation: 1213..1522 -> 309-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      "Ep 4\tScore: 8.16\t\n",
      "4 5\n",
      "Track generation: 1064..1334 -> 270-tiles track\n",
      "Ep 5\tScore: 8.10\t\n",
      "5 5\n",
      "Track generation: 1191..1493 -> 302-tiles track\n",
      "Ep 6\tScore: 5.73\t\n",
      "6 6\n",
      "Track generation: 1092..1369 -> 277-tiles track\n",
      "Ep 7\tScore: 7.49\t\n",
      "7 9\n",
      "Track generation: 1196..1499 -> 303-tiles track\n",
      "Ep 8\tScore: 5.67\t\n",
      "8 10\n",
      "Track generation: 1031..1293 -> 262-tiles track\n",
      "Ep 9\tScore: 8.74\t\n",
      "9 11\n",
      "Track generation: 1064..1334 -> 270-tiles track\n",
      "Ep 10\tScore: 8.05\t\n",
      "10 15\n",
      "Track generation: 1016..1274 -> 258-tiles track\n",
      "Ep 11\tScore: 9.05\t\n",
      "11 16\n",
      "Track generation: 1070..1348 -> 278-tiles track\n",
      "Ep 12\tScore: 6.36\t\n",
      "12 18\n",
      "Track generation: 1142..1436 -> 294-tiles track\n",
      "Ep 13\tScore: 5.83\t\n",
      "13 18\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "Ep 14\tScore: 4.69\t\n",
      "14 22\n",
      "Track generation: 1179..1485 -> 306-tiles track\n",
      "Ep 15\tScore: 5.72\t\n",
      "15 23\n",
      "Track generation: 1095..1373 -> 278-tiles track\n",
      "Ep 16\tScore: 7.36\t\n",
      "16 25\n",
      "Track generation: 1079..1353 -> 274-tiles track\n",
      "Ep 17\tScore: 7.63\t\n",
      "17 27\n",
      "Track generation: 1175..1473 -> 298-tiles track\n",
      "Ep 18\tScore: 6.00\t\n",
      "18 27\n",
      "Track generation: 1271..1593 -> 322-tiles track\n",
      "Ep 19\tScore: 4.44\t\n",
      "19 28\n",
      "Track generation: 1176..1477 -> 301-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1060..1329 -> 269-tiles track\n",
      "Ep 20\tScore: 8.14\t\n",
      "20 30\n",
      "Track generation: 1232..1553 -> 321-tiles track\n",
      "Ep 21\tScore: 5.93\t\n",
      "21 32\n",
      "Track generation: 1188..1497 -> 309-tiles track\n",
      "Ep 22\tScore: 5.13\t\n",
      "22 34\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "Ep 23\tScore: 4.97\t\n",
      "23 36\n",
      "Track generation: 1123..1408 -> 285-tiles track\n",
      "Ep 24\tScore: 6.88\t\n",
      "24 37\n",
      "Track generation: 1264..1584 -> 320-tiles track\n",
      "Ep 25\tScore: 4.31\t\n",
      "25 38\n",
      "Track generation: 1113..1395 -> 282-tiles track\n",
      "Ep 26\tScore: 6.85\t\n",
      "26 39\n",
      "Track generation: 1132..1420 -> 288-tiles track\n",
      "Ep 27\tScore: 6.61\t\n",
      "27 39\n",
      "Track generation: 1012..1273 -> 261-tiles track\n",
      "Ep 28\tScore: 7.98\t\n",
      "28 39\n",
      "Track generation: 1107..1388 -> 281-tiles track\n",
      "Ep 29\tScore: 7.18\t\n",
      "29 41\n",
      "Track generation: 1078..1357 -> 279-tiles track\n",
      "Ep 30\tScore: -18.02\t\n",
      "30 44\n",
      "Track generation: 963..1217 -> 254-tiles track\n",
      "Ep 31\tScore: 8.47\t\n",
      "31 44\n",
      "Track generation: 1101..1384 -> 283-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "Ep 32\tScore: 5.54\t\n",
      "32 46\n",
      "Track generation: 1190..1501 -> 311-tiles track\n",
      "Ep 33\tScore: 7.18\t\n",
      "33 49\n",
      "Track generation: 1068..1339 -> 271-tiles track\n",
      "Ep 34\tScore: 7.92\t\n",
      "34 50\n",
      "Track generation: 1203..1508 -> 305-tiles track\n",
      "Ep 35\tScore: 5.39\t\n",
      "35 52\n",
      "Track generation: 1227..1537 -> 310-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1022..1288 -> 266-tiles track\n",
      "Ep 36\tScore: 7.64\t\n",
      "36 55\n",
      "Track generation: 1255..1573 -> 318-tiles track\n",
      "Ep 37\tScore: 4.48\t\n",
      "37 55\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Ep 38\tScore: 6.06\t\n",
      "38 56\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Ep 39\tScore: 6.16\t\n",
      "39 56\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Ep 40\tScore: 5.86\t\n",
      "40 57\n",
      "Track generation: 969..1223 -> 254-tiles track\n",
      "Ep 41\tScore: 8.52\t\n",
      "41 58\n",
      "Track generation: 1019..1278 -> 259-tiles track\n",
      "Ep 42\tScore: 9.01\t\n",
      "42 62\n",
      "Track generation: 1143..1433 -> 290-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-735a6e379035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mstate_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdie\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# time.sleep(0.05)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ed160d55aada>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mimg_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;31m# don't penalize \"die state\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdie\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\awds2588\\desktop\\college course\\jupyter\\practice\\gymhh\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\awds2588\\desktop\\college course\\jupyter\\practice\\gymhh\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mFPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"state_pixels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mstep_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\awds2588\\desktop\\college course\\jupyter\\practice\\gymhh\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglViewport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVP_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVP_H\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_road\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[0mgeom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\awds2588\\desktop\\college course\\jupyter\\practice\\gymhh\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mrender_road\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolygons_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"v3f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygons_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"c4f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         )  # gl.GL_QUADS,\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mvl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGL_QUADS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[0mvl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \"\"\"\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, mode, vertex_list)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mglPushClientAttrib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGL_CLIENT_VERTEX_ARRAY_BIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_attributes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mattribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexbuffer.py\u001b[0m in \u001b[0;36mbind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m                 \u001b[0mglBufferData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 glBufferSubData(self.target, self._dirty_min, size,\n\u001b[0m\u001b[0;32m    399\u001b[0m                                 self.data_ptr + self._dirty_min)\n\u001b[0;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dirty_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "agent = Agent()\n",
    "agent.load_param()\n",
    "env = Env()\n",
    "\n",
    "training_records = []\n",
    "running_score = 0\n",
    "state = env.reset()\n",
    "\n",
    "X, Y = [], []\n",
    "idx = 1\n",
    "for i_ep in range(5000):\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "\n",
    "    for t in range(1000):\n",
    "        action = agent.select_action(state)\n",
    "        \n",
    "        if random.randint(0,10) == 9:\n",
    "            X.append(state)\n",
    "            Y.append(action)\n",
    "\n",
    "        state_, reward, done, die = env.step(action * np.array([2., 1., 1.]) + np.array([-1.5, 0., 0.]))\n",
    "        # time.sleep(0.05)\n",
    "        # env.render()\n",
    "        score += reward\n",
    "        state = state_\n",
    "        if done or die:\n",
    "            break\n",
    "\n",
    "    print('Ep {}\\tScore: {:.2f}\\t'.format(i_ep, score))\n",
    "\n",
    "    print(i_ep, len(X))\n",
    "    \n",
    "    '''\n",
    "    if i_ep % 1000 == 999: \n",
    "        np.save('features{}.npy'.format(idx), X)\n",
    "        np.save('labels{}.npy'.format(idx), Y)\n",
    "        X, Y = [], []\n",
    "        idx += 1\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b1716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c39d017d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b83dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbf891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7adf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c22adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ab214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a4337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
