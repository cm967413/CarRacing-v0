{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d295c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gym\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7de6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_num = 1\n",
    "\n",
    "for i in range(trajectory_num):\n",
    "    feature_path = os.path.join('expert_trajectory', 'features{}.npy'.format(i))\n",
    "    label_path = os.path.join('expert_trajectory', 'labels{}.npy'.format(i))\n",
    "    if i == 0:\n",
    "        X = np.load(feature_path)\n",
    "        Y = np.load(label_path)\n",
    "    else:\n",
    "        X = np.append(X, np.load(feature_path), axis=0)\n",
    "        Y = np.append(Y, np.load(label_path), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a69c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x: (3796, 4, 96, 96)\n",
      "Train y (3796, 3)\n",
      "Val x: (950, 4, 96, 96)\n",
      "Val y: (950, 3)\n"
     ]
    }
   ],
   "source": [
    "seed = np.random.randint(0, 10000)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(X)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(Y)\n",
    "\n",
    "train_x, val_x= X[:math.floor(len(X)*0.8)], X[math.floor(len(X)*0.8):]\n",
    "train_y, val_y= Y[:math.floor(len(Y)*0.8)], Y[math.floor(len(Y)*0.8):]\n",
    "print(\"Train x:\", train_x.shape)\n",
    "print(\"Train y\", train_y.shape)\n",
    "print(\"Val x:\", val_x.shape)\n",
    "print(\"Val y:\", val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ccd70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.Y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1e6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_set = ImgDataset(train_x, train_y)\n",
    "val_set = ImgDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "for inputs, labels in train_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa324bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 90, 90]           3,152\n",
      "              ReLU-2           [-1, 16, 90, 90]               0\n",
      "            Conv2d-3           [-1, 32, 43, 43]          12,832\n",
      "              ReLU-4           [-1, 32, 43, 43]               0\n",
      "            Conv2d-5           [-1, 64, 21, 21]          18,496\n",
      "              ReLU-6           [-1, 64, 21, 21]               0\n",
      "            Conv2d-7           [-1, 64, 10, 10]          36,928\n",
      "              ReLU-8           [-1, 64, 10, 10]               0\n",
      "            Conv2d-9            [-1, 128, 4, 4]          73,856\n",
      "             ReLU-10            [-1, 128, 4, 4]               0\n",
      "           Conv2d-11            [-1, 128, 1, 1]         147,584\n",
      "             ReLU-12            [-1, 128, 1, 1]               0\n",
      "           Linear-13                  [-1, 256]          33,024\n",
      "             ReLU-14                  [-1, 256]               0\n",
      "           Linear-15                    [-1, 3]             771\n",
      "================================================================\n",
      "Total params: 326,643\n",
      "Trainable params: 326,643\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 3.45\n",
      "Params size (MB): 1.25\n",
      "Estimated Total Size (MB): 4.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self,ch=2):\n",
    "        super(Classifier,self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=4,out_channels=ch*8,kernel_size=7),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=ch*8,out_channels=ch*16,kernel_size=5,stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=ch*16,out_channels=ch*32,kernel_size=3,stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=ch*32,out_channels=ch*32,kernel_size=3,stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=ch*32,out_channels=ch*64,kernel_size=3,stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=ch*64,out_channels=ch*64,kernel_size=3,stride=2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.v = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64*ch*1*1,256),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(256,3)\n",
    "        self.ch = ch\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.v(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        x[:,0] = torch.tanh(x[:,0])\n",
    "        x[:,1] = torch.sigmoid(x[:,1])\n",
    "        x[:,2] = torch.sigmoid(x[:,2])\n",
    "        return x\n",
    "\n",
    "model = Classifier().cuda()\n",
    "summary(model, (4, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56de73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3e0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/100] 1.73 sec(s) Train Loss: 0.000620 | Val loss: 0.000251\n",
      "[002/100] 1.52 sec(s) Train Loss: 0.000184 | Val loss: 0.000198\n",
      "[003/100] 1.54 sec(s) Train Loss: 0.000158 | Val loss: 0.000155\n",
      "[004/100] 1.51 sec(s) Train Loss: 0.000106 | Val loss: 0.000104\n",
      "[005/100] 1.56 sec(s) Train Loss: 0.000086 | Val loss: 0.000100\n",
      "[006/100] 1.53 sec(s) Train Loss: 0.000077 | Val loss: 0.000088\n",
      "[007/100] 1.52 sec(s) Train Loss: 0.000069 | Val loss: 0.000074\n",
      "[008/100] 1.57 sec(s) Train Loss: 0.000060 | Val loss: 0.000076\n",
      "[009/100] 1.59 sec(s) Train Loss: 0.000057 | Val loss: 0.000065\n",
      "[010/100] 1.60 sec(s) Train Loss: 0.000052 | Val loss: 0.000061\n",
      "[011/100] 1.51 sec(s) Train Loss: 0.000049 | Val loss: 0.000055\n",
      "[012/100] 1.52 sec(s) Train Loss: 0.000047 | Val loss: 0.000055\n",
      "[013/100] 1.53 sec(s) Train Loss: 0.000046 | Val loss: 0.000052\n",
      "[014/100] 1.52 sec(s) Train Loss: 0.000044 | Val loss: 0.000054\n",
      "[015/100] 1.51 sec(s) Train Loss: 0.000043 | Val loss: 0.000053\n",
      "[016/100] 1.52 sec(s) Train Loss: 0.000043 | Val loss: 0.000051\n",
      "[017/100] 1.53 sec(s) Train Loss: 0.000042 | Val loss: 0.000050\n",
      "[018/100] 1.51 sec(s) Train Loss: 0.000041 | Val loss: 0.000048\n",
      "[019/100] 1.52 sec(s) Train Loss: 0.000040 | Val loss: 0.000049\n",
      "[020/100] 1.54 sec(s) Train Loss: 0.000039 | Val loss: 0.000048\n",
      "[021/100] 1.51 sec(s) Train Loss: 0.000042 | Val loss: 0.000052\n",
      "[022/100] 1.52 sec(s) Train Loss: 0.000038 | Val loss: 0.000046\n",
      "[023/100] 1.51 sec(s) Train Loss: 0.000036 | Val loss: 0.000046\n",
      "[024/100] 1.52 sec(s) Train Loss: 0.000037 | Val loss: 0.000050\n",
      "[025/100] 1.55 sec(s) Train Loss: 0.000039 | Val loss: 0.000050\n",
      "[026/100] 1.59 sec(s) Train Loss: 0.000036 | Val loss: 0.000045\n",
      "[027/100] 1.59 sec(s) Train Loss: 0.000035 | Val loss: 0.000044\n",
      "[028/100] 1.55 sec(s) Train Loss: 0.000034 | Val loss: 0.000048\n",
      "[029/100] 1.56 sec(s) Train Loss: 0.000035 | Val loss: 0.000042\n",
      "[030/100] 1.61 sec(s) Train Loss: 0.000034 | Val loss: 0.000043\n",
      "[031/100] 1.52 sec(s) Train Loss: 0.000032 | Val loss: 0.000042\n",
      "[032/100] 1.53 sec(s) Train Loss: 0.000034 | Val loss: 0.000047\n",
      "[033/100] 1.51 sec(s) Train Loss: 0.000035 | Val loss: 0.000042\n",
      "[034/100] 1.53 sec(s) Train Loss: 0.000033 | Val loss: 0.000041\n",
      "[035/100] 1.51 sec(s) Train Loss: 0.000032 | Val loss: 0.000042\n",
      "[036/100] 1.52 sec(s) Train Loss: 0.000031 | Val loss: 0.000040\n",
      "[037/100] 1.51 sec(s) Train Loss: 0.000031 | Val loss: 0.000039\n",
      "[038/100] 1.52 sec(s) Train Loss: 0.000030 | Val loss: 0.000041\n",
      "[039/100] 1.51 sec(s) Train Loss: 0.000031 | Val loss: 0.000044\n",
      "[040/100] 1.53 sec(s) Train Loss: 0.000031 | Val loss: 0.000040\n",
      "[041/100] 1.52 sec(s) Train Loss: 0.000031 | Val loss: 0.000044\n",
      "[042/100] 1.53 sec(s) Train Loss: 0.000029 | Val loss: 0.000039\n",
      "[043/100] 1.53 sec(s) Train Loss: 0.000030 | Val loss: 0.000037\n",
      "[044/100] 1.52 sec(s) Train Loss: 0.000029 | Val loss: 0.000039\n",
      "[045/100] 1.52 sec(s) Train Loss: 0.000030 | Val loss: 0.000039\n",
      "[046/100] 1.52 sec(s) Train Loss: 0.000028 | Val loss: 0.000038\n",
      "[047/100] 1.54 sec(s) Train Loss: 0.000029 | Val loss: 0.000042\n",
      "[048/100] 1.63 sec(s) Train Loss: 0.000029 | Val loss: 0.000037\n",
      "[049/100] 1.62 sec(s) Train Loss: 0.000027 | Val loss: 0.000041\n",
      "[050/100] 1.54 sec(s) Train Loss: 0.000026 | Val loss: 0.000038\n",
      "[051/100] 1.55 sec(s) Train Loss: 0.000027 | Val loss: 0.000038\n",
      "[052/100] 1.53 sec(s) Train Loss: 0.000026 | Val loss: 0.000035\n",
      "[053/100] 1.52 sec(s) Train Loss: 0.000027 | Val loss: 0.000036\n",
      "[054/100] 1.54 sec(s) Train Loss: 0.000026 | Val loss: 0.000040\n",
      "[055/100] 1.58 sec(s) Train Loss: 0.000027 | Val loss: 0.000035\n",
      "[056/100] 1.59 sec(s) Train Loss: 0.000027 | Val loss: 0.000037\n",
      "[057/100] 1.56 sec(s) Train Loss: 0.000026 | Val loss: 0.000037\n",
      "[058/100] 1.55 sec(s) Train Loss: 0.000026 | Val loss: 0.000037\n",
      "[059/100] 1.60 sec(s) Train Loss: 0.000025 | Val loss: 0.000036\n",
      "[060/100] 1.62 sec(s) Train Loss: 0.000025 | Val loss: 0.000036\n",
      "[061/100] 1.60 sec(s) Train Loss: 0.000026 | Val loss: 0.000036\n",
      "[062/100] 1.58 sec(s) Train Loss: 0.000024 | Val loss: 0.000036\n",
      "[063/100] 1.60 sec(s) Train Loss: 0.000025 | Val loss: 0.000034\n",
      "[064/100] 1.65 sec(s) Train Loss: 0.000024 | Val loss: 0.000035\n",
      "[065/100] 1.56 sec(s) Train Loss: 0.000025 | Val loss: 0.000035\n",
      "[066/100] 1.60 sec(s) Train Loss: 0.000024 | Val loss: 0.000034\n",
      "[067/100] 1.69 sec(s) Train Loss: 0.000025 | Val loss: 0.000037\n",
      "[068/100] 1.63 sec(s) Train Loss: 0.000023 | Val loss: 0.000034\n",
      "[069/100] 1.54 sec(s) Train Loss: 0.000024 | Val loss: 0.000039\n",
      "[070/100] 1.65 sec(s) Train Loss: 0.000024 | Val loss: 0.000037\n",
      "[071/100] 1.58 sec(s) Train Loss: 0.000023 | Val loss: 0.000036\n",
      "[072/100] 1.51 sec(s) Train Loss: 0.000024 | Val loss: 0.000038\n",
      "[073/100] 1.54 sec(s) Train Loss: 0.000023 | Val loss: 0.000033\n",
      "[074/100] 1.56 sec(s) Train Loss: 0.000022 | Val loss: 0.000036\n",
      "[075/100] 1.58 sec(s) Train Loss: 0.000022 | Val loss: 0.000035\n",
      "[076/100] 1.56 sec(s) Train Loss: 0.000022 | Val loss: 0.000034\n",
      "[077/100] 1.70 sec(s) Train Loss: 0.000022 | Val loss: 0.000034\n",
      "[078/100] 1.65 sec(s) Train Loss: 0.000022 | Val loss: 0.000034\n",
      "[079/100] 1.68 sec(s) Train Loss: 0.000021 | Val loss: 0.000038\n",
      "[080/100] 1.70 sec(s) Train Loss: 0.000024 | Val loss: 0.000040\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().cuda()\n",
    "loss = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        train_pred = model(data[0].cuda().float())\n",
    "        batch_loss = loss(train_pred, data[1].cuda()).cuda() # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "        \n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda().float())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Loss: %3.6f | Val loss: %3.6f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, train_loss/train_set.__len__(), val_loss/val_set.__len__()))\n",
    "    \n",
    "    torch.save(model, 'save.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eede79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'save.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "585a6762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dagger'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a1b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f2c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fbc1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
